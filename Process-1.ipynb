{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The filename, directory name, or volume label syntax is incorrect.\n"
     ]
    }
   ],
   "source": [
    "pip install matrix_factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChrisLex\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\ChrisLex\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\ChrisLex\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Librerías de procesamiento y transformación de datos\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from math import pow, sqrt\n",
    "\n",
    "# Modelo de predicción\n",
    "from matrix_factorization import BaselineModel, KernelMF, train_update_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Otras Librerías \n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                  Type                          Data/Info\n",
      "-----------------------------------------------------------------\n",
      "BaselineModel             ABCMeta                       <class 'matrix_factorizat<...>ine_model.BaselineModel'>\n",
      "KernelMF                  ABCMeta                       <class 'matrix_factorizat<...>_factorization.KernelMF'>\n",
      "csv                       module                        <module 'csv' from 'C:\\\\U<...>\\anaconda3\\\\lib\\\\csv.py'>\n",
      "date                      type                          <class 'datetime.date'>\n",
      "datetime                  type                          <class 'datetime.datetime'>\n",
      "mean_squared_error        function                      <function mean_squared_er<...>or at 0x0000021724A83550>\n",
      "np                        module                        <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "os                        module                        <module 'os' from 'C:\\\\Us<...>\\\\anaconda3\\\\lib\\\\os.py'>\n",
      "pd                        module                        <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "pow                       builtin_function_or_method    <built-in function pow>\n",
      "random                    module                        <module 'random' from 'C:<...>aconda3\\\\lib\\\\random.py'>\n",
      "sqrt                      builtin_function_or_method    <built-in function sqrt>\n",
      "sys                       module                        <module 'sys' (built-in)>\n",
      "train_test_split          function                      <function train_test_split at 0x00000217249674C0>\n",
      "train_update_test_split   function                      <function train_update_te<...>it at 0x0000021724911550>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menor año del dataset:\n",
      "1995\n",
      "Mayor año del dataset:\n",
      "2019\n",
      "Numero de registros archivo inicial: \n",
      "25000096\n"
     ]
    }
   ],
   "source": [
    "#DESCRIPCION DATASET\n",
    "#MovieLens 25M movie ratings. Stable benchmark dataset. 25 million ratings and one million tag applications applied to 62,000 movies by 162,000 users. Includes tag genome data with 15 million relevance scores across 1,129 tags. Released 12/2019\n",
    "\n",
    "#Division del dataset MovieLens rating.csv cinco bloques 1995-1999, 2000-2004, 2005-2009, 2010-2014, 2015-2019\n",
    "#Bloque1 (1995-1999) 3387477 registros\n",
    "#Bloque2 (2000-2004) 5539213 registros\n",
    "#Bloque3 (2005-2009) 5411568 registros\n",
    "#Bloque4 (2010-2014) 3098096 registros\n",
    "#Bloque5 (2015-2019) 7563741 registros\n",
    "\n",
    "df = pd.read_csv('ratings.csv')\n",
    "\n",
    "#Ordenar los datos por el campo timestamp\n",
    "mdf = df.sort_values(by='timestamp').reset_index(drop=True)\n",
    "fecha = date.fromtimestamp(mdf['timestamp'].iloc[0])\n",
    "print('Menor año del dataset:')\n",
    "print(fecha.year)\n",
    "\n",
    "fecha = date.fromtimestamp(mdf['timestamp'].iloc[-1])\n",
    "print('Mayor año del dataset:')\n",
    "print(fecha.year)\n",
    "\n",
    "#Numero de registros inicial\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('ratings.csv'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros archivo inicial: \")\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 09:55:49\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de registros Bloque 1: \n",
      "3387818\n"
     ]
    }
   ],
   "source": [
    "#/////////////////////////////////////////////////////////////////////#\n",
    "#Generación del Bloque1 (1995-1999) \n",
    "\n",
    "f = open('ratingsBloque0011.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['userId','mmovieId','rating','timestamp'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    fecha = date.fromtimestamp(row['timestamp'])\n",
    "    if(fecha.year >= 1995 and fecha.year <= 1999):\n",
    "        if any(row):\n",
    "            writer.writerow(row)\n",
    "        \n",
    "f.close()\n",
    "\n",
    "with open('ratingsBloque0011.csv') as input, open('ratingsBloque001.csv', 'w', newline='') as output:\n",
    "     writer = csv.writer(output)\n",
    "     for row in csv.reader(input):\n",
    "         if any(field.strip() for field in row):\n",
    "             writer.writerow(row)\n",
    "\n",
    "#Numero de registros Bloque 1\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('ratingsBloque001.csv'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros Bloque 1: \")\n",
    "print(num_rows)\n",
    "os.remove(\"ratingsBloque0011.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 10:36:08\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de registros Bloque 2: \n",
      "5540270\n"
     ]
    }
   ],
   "source": [
    "#/////////////////////////////////////////////////////////////////////#\n",
    "\n",
    "#Generación del Bloque2 (2000-2004) \n",
    "f = open('ratingsBloque0022.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['userId','mmovieId','rating','timestamp'])\n",
    "\n",
    "for index, row in mdf.iterrows():\n",
    "    fecha = date.fromtimestamp(row['timestamp'])\n",
    "    if(fecha.year >= 2000 and fecha.year <= 2004):\n",
    "        if any(row):\n",
    "            writer.writerow(row)\n",
    "            \n",
    "f.close()\n",
    "\n",
    "with open('ratingsBloque0022.csv') as input, open('ratingsBloque002.csv', 'w', newline='') as output:\n",
    "     writer = csv.writer(output)\n",
    "     for row in csv.reader(input):\n",
    "         if any(field.strip() for field in row):\n",
    "             writer.writerow(row)\n",
    "\n",
    "#Numero de registros Bloque 2\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('ratingsBloque002.csv'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros Bloque 2: \")\n",
    "print(num_rows)\n",
    "os.remove(\"ratingsBloque0022.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 11:17:17\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de registros Bloque 3: \n",
      "5410624\n"
     ]
    }
   ],
   "source": [
    "#/////////////////////////////////////////////////////////////////////#\n",
    "\n",
    "#Generación del Bloque3 (2005-2009) \n",
    "f = open('ratingsBloque0033.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['userId','mmovieId','rating','timestamp'])\n",
    "\n",
    "for index, row in mdf.iterrows():\n",
    "    fecha = date.fromtimestamp(row['timestamp'])\n",
    "    if(fecha.year >= 2005 and fecha.year <= 2009):\n",
    "        if any(row):\n",
    "            writer.writerow(row)\n",
    "f.close()\n",
    "\n",
    "with open('ratingsBloque0033.csv') as input, open('ratingsBloque003.csv', 'w', newline='') as output:\n",
    "     writer = csv.writer(output)\n",
    "     for row in csv.reader(input):\n",
    "         if any(field.strip() for field in row):\n",
    "             writer.writerow(row)\n",
    "            \n",
    "#Numero de registros Bloque 3\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('ratingsBloque003.csv'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros Bloque 3: \")\n",
    "print(num_rows)\n",
    "os.remove(\"ratingsBloque0033.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 11:58:18\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de registros Bloque 4: \n",
      "3098066\n"
     ]
    }
   ],
   "source": [
    "#/////////////////////////////////////////////////////////////////////#\n",
    "\n",
    "#Generación del Bloque4 (2010-2014) \n",
    "f = open('ratingsBloque0044.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['userId','mmovieId','rating','timestamp'])\n",
    "for index, row in mdf.iterrows():\n",
    "    fecha = date.fromtimestamp(row['timestamp'])\n",
    "    if(fecha.year >= 2010 and fecha.year <= 2014):\n",
    "        if any(row):\n",
    "            writer.writerow(row)\n",
    "    \n",
    "f.close()\n",
    "\n",
    "with open('ratingsBloque0044.csv') as input, open('ratingsBloque004.csv', 'w', newline='') as output:\n",
    "     writer = csv.writer(output)\n",
    "     for row in csv.reader(input):\n",
    "         if any(field.strip() for field in row):\n",
    "             writer.writerow(row)\n",
    "\n",
    "#Numero de registros Bloque 4\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('ratingsBloque004.csv'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros Bloque 4: \")\n",
    "print(num_rows)\n",
    "os.remove(\"ratingsBloque0044.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 12:38:10\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de registros Bloque 5: \n",
      "7563322\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Generación del Bloque5 (2015-2019)\n",
    "f = open('ratingsBloque0055.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['userId','mmovieId','rating','timestamp'])\n",
    "\n",
    "for index, row in mdf.iterrows():\n",
    "    fecha = date.fromtimestamp(row['timestamp'])\n",
    "    if(fecha.year >= 2015 and fecha.year <= 2019):\n",
    "        if any(row):\n",
    "            writer.writerow(row)\n",
    "    \n",
    "f.close()\n",
    "\n",
    "with open('ratingsBloque0055.csv') as input, open('ratingsBloque005.csv', 'w', newline='') as output:\n",
    "     writer = csv.writer(output)\n",
    "     for row in csv.reader(input):\n",
    "         if any(field.strip() for field in row):\n",
    "             writer.writerow(row)\n",
    "\n",
    "#Numero de registros Bloque 5\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('ratingsBloque005.csv'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros Bloque 5: \")\n",
    "print(num_rows)\n",
    "os.remove(\"ratingsBloque0055.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 13:20:26\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios comunes entre los bloques 3,4 y 5 (2005-2019) : \n",
      "1835\n",
      "Películas comunes entre los bloques 3,4 y 5 (2005-2019) : \n",
      "11824\n"
     ]
    }
   ],
   "source": [
    "#Los bloques 3,4,5 son seleccionados para trabajar en este proyecto ya que son los bloques con datos más actuales \n",
    "#y con una mayor cantidad de registros.\n",
    "df003 = pd.read_csv('ratingsBloque003.csv')\n",
    "df004 = pd.read_csv('ratingsBloque004.csv')\n",
    "df005 = pd.read_csv('ratingsBloque005.csv')\n",
    "\n",
    "#USUARIOS COMUNES PARA LOS BLOQUES 3,4 Y 5\n",
    "#Usuarios únicos del bloque 3\n",
    "user_ids003 = df003['userId'].values.tolist()\n",
    "unique_users003 = set(user_ids003) \n",
    "\n",
    "#Usuarios únicos del bloque 4\n",
    "user_ids004 = df004['userId'].values.tolist()\n",
    "unique_users004 = set(user_ids004) \n",
    "\n",
    "#Usuarios únicos del bloque 5\n",
    "user_ids005 = df005['userId'].values.tolist()\n",
    "unique_users005 = set(user_ids005) \n",
    "\n",
    "#Intersección de usuarios comunes de los tres bloques \n",
    "result = unique_users003.intersection(unique_users004,unique_users005)\n",
    "resultCountTODOS = len(result)\n",
    "print('Usuarios comunes entre los bloques 3,4 y 5 (2005-2019) : ')\n",
    "print(resultCountTODOS)\n",
    "\n",
    "#PELICULAS COMUNES PARA LOS BLOQUES 3,4 Y 5\n",
    "#Películas únicas del bloque 3\n",
    "item_ids003 = df003['mmovieId'].values.tolist()\n",
    "unique_movies003 = set(item_ids003) \n",
    "#Películas únicas del bloque 4\n",
    "item_ids004 = df004['mmovieId'].values.tolist()\n",
    "unique_movies004 = set(item_ids004) \n",
    "#Películas únicas del bloque 5\n",
    "item_ids005 = df005['mmovieId'].values.tolist()\n",
    "unique_movies005 = set(item_ids005) \n",
    "resultMovies = unique_movies003.intersection(unique_movies004,unique_movies005)\n",
    "\n",
    "#Intersección de peliculas comunes de los tres bloques \n",
    "resultCountTODOSMovies = len(resultMovies)\n",
    "print('Películas comunes entre los bloques 3,4 y 5 (2005-2019) : ')\n",
    "print(resultCountTODOSMovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 13:20:43\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESO DE ELIMINACION DE REGISTROS CON FRECUENCIA DE REPETICION = 1 PARA USUARIO, PELICULA Y PELICULA-USUARIO\n",
    "###########################################################################################\n",
    "#BLOQUE 3\n",
    "df003_5 = pd.read_csv('ratingsBloque003.csv')\n",
    "\n",
    "#Eliminados las películas con frecuencia de repetición = 1 para el Bloque 3\n",
    "df003_5['freq'] = df003_5.groupby('mmovieId')['mmovieId'].transform('count')\n",
    "df003_5.sort_values(by=['freq'], inplace=True)\n",
    "df003_5 = df003_5.drop(df003_5[df003_5.freq < 2].index)\n",
    "df003_5.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "#Eliminados los usuarios con frecuencia de repetición = 1 para el Bloque 3\n",
    "df003_5['freq'] = df003_5.groupby('userId')['userId'].transform('count')\n",
    "df003_5.sort_values(by=['freq'], inplace=True)\n",
    "df003_5 = df003_5.drop(df003_5[df003_5.freq < 2].index)\n",
    "df003_5.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "#Eliminados las combinaciones usuario y pelicula con frecuencia de repetición = 1 para el Bloque 3\n",
    "df003_5['freq'] = df003_5.groupby('mmovieId')['userId'].transform('count')\n",
    "df003_5.sort_values(by=['freq'], inplace=True)\n",
    "df003_5 = df003_5.drop(df003_5[df003_5.freq < 2].index)\n",
    "df003_5.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "#Generación de dataset para Bloque 3, sin registros de peliculas únicas, y con registros películas y usuarios comunes \n",
    "#para los tres bloques\n",
    "mdf003_5 = df003_5.sort_values(by='timestamp').reset_index(drop=True)\n",
    "mdf003_5 = mdf003_5[mdf003_5.duplicated(subset=[\"userId\"], keep=False)]\n",
    "f = open('ratingsSinRegUnicosBloque003.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['userId','mmovieId','rating','timestamp'])\n",
    "for index, row in mdf003_5.iterrows():\n",
    "    if(row['userId'] in result):\n",
    "      if(row['mmovieId'] in resultMovies):\n",
    "        writer.writerow(row)\n",
    "f.close()\n",
    "\n",
    "###################################################################################################\n",
    "#BLOQUE 4\n",
    "df004_5 = pd.read_csv('ratingsBloque004.csv')\n",
    "\n",
    "#Eliminados las películas con frecuencia de repetición = 1 para el Bloque 3\n",
    "df004_5['freq'] = df004_5.groupby('mmovieId')['mmovieId'].transform('count')\n",
    "df004_5.sort_values(by=['freq'], inplace=True)\n",
    "df004_5 = df004_5.drop(df004_5[df004_5.freq < 2].index)\n",
    "df004_5.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "#Eliminados los usuarios con frecuencia de repetición = 1 para el Bloque 3\n",
    "df004_5['freq'] = df004_5.groupby('userId')['userId'].transform('count')\n",
    "df004_5.sort_values(by=['freq'], inplace=True)\n",
    "df004_5 = df004_5.drop(df004_5[df004_5.freq < 2].index)\n",
    "df004_5.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "#Eliminados las combinaciones usuario y pelicula con frecuencia de repetición = 1 para el Bloque 4\n",
    "df004_5['freq'] = df004_5.groupby('mmovieId')['userId'].transform('count')\n",
    "df004_5.sort_values(by=['freq'], inplace=True)\n",
    "df004_5 = df004_5.drop(df004_5[df004_5.freq < 2].index)\n",
    "df004_5.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "#Generación de dataset para Bloque 4, sin registros de de peliculas únicas, y con registros de películas y usuarios comunes para los tres bloques\n",
    "mdf004_5 = df004_5.sort_values(by='timestamp').reset_index(drop=True)\n",
    "mdf004_5 = mdf004_5[mdf004_5.duplicated(subset=[\"userId\"], keep=False)]\n",
    "f = open('ratingsSinRegUnicosBloque004.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['userId','mmovieId','rating','timestamp'])\n",
    "for index, row in mdf004_5.iterrows():\n",
    "    if(row['userId'] in result):\n",
    "      if(row['mmovieId'] in resultMovies):\n",
    "        writer.writerow(row)\n",
    "f.close()\n",
    "\n",
    "#########################################################################################################\n",
    "#BLOQUE 5\n",
    "df005_5 = pd.read_csv('ratingsBloque005.csv')\n",
    "\n",
    "#Eliminados las películas con frecuencia de repetición = 1 para el Bloque 5\n",
    "df005_5['freq'] = df005_5.groupby('mmovieId')['mmovieId'].transform('count')\n",
    "df005_5.sort_values(by=['freq'], inplace=True)\n",
    "df005_5 = df005_5.drop(df005_5[df005_5.freq < 2].index)\n",
    "df005_5.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "#Eliminados los usuarios con frecuencia de repetición = 1 para el Bloque 5\n",
    "df005_5['freq'] = df005_5.groupby('userId')['userId'].transform('count')\n",
    "df005_5.sort_values(by=['freq'], inplace=True)\n",
    "df005_5 = df005_5.drop(df005_5[df005_5.freq < 2].index)\n",
    "df005_5.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "#Eliminados las combinaciones usuario y pelicula con frecuencia de repetición = 1 para el Bloque 5\n",
    "df005_5['freq'] = df005_5.groupby('mmovieId')['userId'].transform('count')\n",
    "df005_5.sort_values(by=['freq'], inplace=True)\n",
    "df005_5 = df005_5.drop(df005_5[df005_5.freq < 2].index)\n",
    "df005_5.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "#Generación de dataset para Bloque 4, sin registros de de peliculas únicas, y con registros \n",
    "# de películas y usuarios comunes para los tres bloques\n",
    "mdf005_5 = df005_5.sort_values(by='timestamp').reset_index(drop=True)\n",
    "mdf005_5 = mdf005_5[mdf005_5.duplicated(subset=[\"userId\"], keep=False)]\n",
    "f = open('ratingsSinRegUnicosBloque005.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['userId','mmovieId','rating','timestamp'])\n",
    "for index, row in mdf005_5.iterrows():\n",
    "    if(row['userId'] in result):\n",
    "      if(row['mmovieId'] in resultMovies):\n",
    "        writer.writerow(row)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 13:46:45\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          userId  mmovieId  rating     timestamp\n",
      "0       120792.0    3608.0     3.5  1.261972e+09\n",
      "1       103126.0   62374.0     2.0  1.242485e+09\n",
      "2       103126.0    2959.0     5.0  1.248683e+09\n",
      "3        48784.0    5481.0     3.0  1.160409e+09\n",
      "4        34480.0    1262.0     4.0  1.108229e+09\n",
      "...          ...       ...     ...           ...\n",
      "656286   20055.0     180.0     1.5  1.163338e+09\n",
      "656287   20055.0    7992.0     2.5  1.177909e+09\n",
      "656288   20055.0    8966.0     4.0  1.169099e+09\n",
      "656289   20055.0    5971.0     4.5  1.170732e+09\n",
      "656290   20055.0   71462.0     4.0  1.260094e+09\n",
      "\n",
      "[656291 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#VALIDACION DE USUARIOS COMUNES Y PELICULAS COMUNES FINAL\n",
    "df003 = pd.read_csv('ratingsSinRegUnicosBloque003.csv')\n",
    "\n",
    "df003['freq'] = df003.groupby('mmovieId')['mmovieId'].transform('count')\n",
    "df003.sort_values(by=['freq'], inplace=True)\n",
    "df003 = df003.drop(df003[df003.freq < 2].index)\n",
    "df003.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "df003['freq'] = df003.groupby('userId')['userId'].transform('count')\n",
    "df003.sort_values(by=['freq'], inplace=True)\n",
    "df003 = df003.drop(df003[df003.freq < 2].index)\n",
    "df003.drop(['freq'], axis='columns', inplace=True)\n",
    "df003['freq'] = df003.groupby('userId')['mmovieId'].transform('count')\n",
    "df003.sort_values(by=['freq'], inplace=True)\n",
    "df003 = df003.drop(df003[df003.freq < 2].index)\n",
    "\n",
    "df003.drop(['freq'], axis='columns', inplace=True)\n",
    "f = open('ratingsSinRegUnicosBloque003Final.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "with open('ratingsSinRegUnicosBloque003Final.csv', 'a') as f:\n",
    "    df003.to_csv(f, header=f.tell()==0,index=False)\n",
    "f.close()\n",
    "df003 = pd.read_csv('ratingsSinRegUnicosBloque003Final.csv')\n",
    "print(df003)\n",
    "\n",
    "\n",
    "df004 = pd.read_csv('ratingsSinRegUnicosBloque004.csv')\n",
    "\n",
    "df004['freq'] = df004.groupby('mmovieId')['mmovieId'].transform('count')\n",
    "df004.sort_values(by=['freq'], inplace=True)\n",
    "df004 = df004.drop(df004[df004.freq < 2].index)\n",
    "df004.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "df004['freq'] = df004.groupby('userId')['userId'].transform('count')\n",
    "df004.sort_values(by=['freq'], inplace=True)\n",
    "df004 = df004.drop(df004[df004.freq < 2].index)\n",
    "df004.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "df004['freq'] = df004.groupby('userId')['mmovieId'].transform('count')\n",
    "df004.sort_values(by=['freq'], inplace=True)\n",
    "df004 = df004.drop(df004[df004.freq < 2].index)\n",
    "\n",
    "df004.drop(['freq'], axis='columns', inplace=True)\n",
    "f = open('ratingsSinRegUnicosBloque004Final.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "with open('ratingsSinRegUnicosBloque004Final.csv', 'a') as f:\n",
    "    df004.to_csv(f, header=f.tell()==0,index=False)\n",
    "f.close()\n",
    "df004 = pd.read_csv('ratingsSinRegUnicosBloque004Final.csv')\n",
    "\n",
    "\n",
    "df005 = pd.read_csv('ratingsSinRegUnicosBloque005.csv')\n",
    "\n",
    "df005['freq'] = df005.groupby('mmovieId')['mmovieId'].transform('count')\n",
    "df005.sort_values(by=['freq'], inplace=True)\n",
    "df005 = df005.drop(df005[df005.freq < 2].index)\n",
    "df005.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "df005['freq'] = df005.groupby('userId')['userId'].transform('count')\n",
    "df005.sort_values(by=['freq'], inplace=True)\n",
    "df005 = df005.drop(df005[df005.freq < 2].index)\n",
    "df005.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "df005['freq'] = df005.groupby('userId')['mmovieId'].transform('count')\n",
    "df005.sort_values(by=['freq'], inplace=True)\n",
    "df005 = df005.drop(df005[df005.freq < 2].index)\n",
    "df005.drop(['freq'], axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "f = open('ratingsSinRegUnicosBloque005Final.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "with open('ratingsSinRegUnicosBloque005Final.csv', 'a') as f:\n",
    "    df005.to_csv(f, header=f.tell()==0,index=False)\n",
    "f.close()\n",
    "df003 = pd.read_csv('ratingsSinRegUnicosBloque005Final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 13:46:58\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1830\n",
      "1811\n",
      "1657\n",
      "Intersección usuarios 2005-2019 : \n",
      "1637\n",
      "****************************************\n",
      "10834\n",
      "8928\n",
      "8009\n",
      "Intersección películas 2005-2019 : \n",
      "7145\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "df003 = pd.read_csv('ratingsSinRegUnicosBloque003Final.csv')\n",
    "df004 = pd.read_csv('ratingsSinRegUnicosBloque004Final.csv')\n",
    "df005 = pd.read_csv('ratingsSinRegUnicosBloque005Final.csv')\n",
    "\n",
    "#USUARIOS COMUNES ENTRE LOS TRES BLOQUES\n",
    "user_ids003 = df003['userId'].values.tolist()\n",
    "unique_users003 = set(user_ids003) \n",
    "print(len(unique_users003))\n",
    "\n",
    "user_ids004 = df004['userId'].values.tolist()\n",
    "unique_users004 = set(user_ids004) \n",
    "print(len(unique_users004))\n",
    "\n",
    "user_ids005 = df005['userId'].values.tolist()\n",
    "unique_users005 = set(user_ids005) \n",
    "print(len(unique_users005))\n",
    "\n",
    "result0 = unique_users003.intersection(unique_users004,unique_users005)\n",
    "resultCountTODOS = len(result0)\n",
    "print('Intersección usuarios 2005-2019 : ')\n",
    "print(resultCountTODOS)\n",
    "print('****************************************')\n",
    "#USUARIOS COMUNES ENTRE LOS TRES BLOQUES\n",
    "item_ids003 = df003['mmovieId'].values.tolist()\n",
    "unique_movies003 = set(item_ids003) \n",
    "print(len(unique_movies003))\n",
    "\n",
    "item_ids004 = df004['mmovieId'].values.tolist()\n",
    "unique_movies004 = set(item_ids004) \n",
    "print(len(unique_movies004))\n",
    "\n",
    "item_ids005 = df005['mmovieId'].values.tolist()\n",
    "unique_movies005 = set(item_ids005) \n",
    "print(len(unique_movies005))\n",
    "\n",
    "resultMovies0 = unique_movies005.intersection(unique_movies003,unique_movies004)\n",
    "resultCountTODOSMovies = len(resultMovies0)\n",
    "print('Intersección películas 2005-2019 : ')\n",
    "print(resultCountTODOSMovies)\n",
    "print('****************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 13:47:00\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CSV to tab-delimited file...\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "\n",
    "#PROCESO DE TRANSFOMACION DE ARCHIVO CSV A CSV DELIMINTADO POR TABULACIONES\n",
    "\n",
    "# Convert comma-delimited CSV files to pipe-delimited files\n",
    "# Usage: Drag-and-drop CSV file over script to convert it.\n",
    "\n",
    "print(\"Converting CSV to tab-delimited file...\")\n",
    "#BLOQUE 3\n",
    "inputPath3 = 'ratingsSinRegUnicosBloque003Final.csv'\n",
    "outputPath3 = 'ratingsTabs003Final.csv'\n",
    "with open(inputPath3) as inputFile:\n",
    "  with open(outputPath3, 'w', newline='') as outputFile:\n",
    "    reader = csv.DictReader(inputFile, delimiter=',')\n",
    "    writer = csv.DictWriter(outputFile, reader.fieldnames, delimiter='\\t')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(reader)\n",
    "\n",
    "\n",
    "#BLOQUE 4\n",
    "inputPath4 = 'ratingsSinRegUnicosBloque004Final.csv'\n",
    "outputPath4 = 'ratingsTabs004Final.csv'\n",
    "with open(inputPath4) as inputFile:\n",
    "  with open(outputPath4, 'w', newline='') as outputFile:\n",
    "    reader = csv.DictReader(inputFile, delimiter=',')\n",
    "    writer = csv.DictWriter(outputFile, reader.fieldnames, delimiter='\\t')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(reader)\n",
    "\n",
    "#BLOQUE 5\n",
    "inputPath5 = 'ratingsSinRegUnicosBloque005Final.csv'\n",
    "outputPath5 = 'ratingsTabs005Final.csv'\n",
    "with open(inputPath5) as inputFile:\n",
    "  with open(outputPath5, 'w', newline='') as outputFile:\n",
    "    reader = csv.DictReader(inputFile, delimiter=',')\n",
    "    writer = csv.DictWriter(outputFile, reader.fieldnames, delimiter='\\t')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 13:47:15\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformación de extensión de archivos .csv a .data\n",
    "import os\n",
    "os.remove(\"ratingsTabs003Final.data\")\n",
    "os.remove(\"ratingsTabs004Final.data\")\n",
    "os.remove(\"ratingsTabs005Final.data\")\n",
    "\n",
    "#BORRADO\n",
    "import shutil\n",
    "shutil.copy2('ratingsTabs003Final.csv', 'ratingsTabs3Final.csv') \n",
    "pre, ext = os.path.splitext('ratingsTabs003Final.csv')\n",
    "os.rename('ratingsTabs003Final.csv', pre + '.data')\n",
    "\n",
    "shutil.copy2('ratingsTabs004Final.csv', 'ratingsTabs4Final.csv') \n",
    "pre, ext = os.path.splitext('ratingsTabs004Final.csv')\n",
    "os.rename('ratingsTabs004Final.csv', pre + '.data')\n",
    "\n",
    "shutil.copy2('ratingsTabs005Final.csv', 'ratingsTabs5Final.csv') \n",
    "pre, ext = os.path.splitext('ratingsTabs005Final.csv')\n",
    "os.rename('ratingsTabs005Final.csv', pre + '.data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 19:30:04\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete.\n"
     ]
    }
   ],
   "source": [
    "#ELIMINACION DE LA PRIMERA FILA DEL DATASET\n",
    "inputPath_3 = 'ratingsTabs003Final.data'\n",
    "inputPath_4 = 'ratingsTabs004Final.data'\n",
    "inputPath_5 = 'ratingsTabs005Final.data'\n",
    "outputPath3 = 'ratingsTabs003.data'\n",
    "outputPath4 = 'ratingsTabs004.data'\n",
    "outputPath5 = 'ratingsTabs005.data'\n",
    "outputPath = 'ratingsTabsFinal.data'\n",
    "\n",
    "\n",
    "\n",
    "#GENERACION DE ARCHIVO BLOQUE 3 SIN CABECERA\n",
    "with open(inputPath_3,'r') as f:\n",
    "    with open(outputPath3,'w') as f1:\n",
    "        next(f) # skip header line\n",
    "        for line in f:\n",
    "            f1.write(line)\n",
    "            \n",
    "#GENERACION DE ARCHIVO BLOQUE 4 SIN CABECERA\n",
    "with open(inputPath_4,'r') as f:\n",
    "    with open(outputPath4,'w') as f1:\n",
    "        next(f) # skip header line\n",
    "        for line in f:\n",
    "            f1.write(line)\n",
    "            \n",
    "#GENERACION DE ARCHIVO BLOQUE 5 SIN CABECERA\n",
    "with open(inputPath_5,'r') as f:\n",
    "    with open(outputPath5,'w') as f1:\n",
    "        next(f) # skip header line\n",
    "        for line in f:\n",
    "            f1.write(line)\n",
    "            \n",
    "            \n",
    "#GENERACION DE ARCHIVO CONJUNTO (BLOQUE3+BLOQUE4+BLOQUE5) SIN CABECERA\n",
    "with open(outputPath3,'r') as f3:\n",
    "    data3 = f3.read()\n",
    "\n",
    "with open(outputPath4,'r') as f4:  \n",
    "    data4 = f4.read()\n",
    "\n",
    "with open(outputPath5,'r') as f5: \n",
    "    data5 = f5.read()\n",
    "\n",
    "data3 += \"\\n\"\n",
    "data3 += data4\n",
    "data3 += \"\\n\"\n",
    "data3 += data5   \n",
    "\n",
    "with open(outputPath,'w') as f1:\n",
    "    f1.write(data3)\n",
    "\n",
    "print(\"Conversion complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 19:30:11\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de registros Bloque 3: \n",
      "656291\n",
      "Numero de registros Bloque 4: \n",
      "218613\n",
      "Numero de registros Bloque 5: \n",
      "113796\n",
      "Numero de registros totales: \n",
      "988702\n"
     ]
    }
   ],
   "source": [
    "#Numero de registros Bloque 3\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('ratingsTabs003.data'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros Bloque 3: \")\n",
    "print(num_rows)\n",
    "\n",
    "#Numero de registros Bloque 4\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('ratingsTabs004.data'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros Bloque 4: \")\n",
    "print(num_rows)\n",
    "\n",
    "\n",
    "#Numero de registros Bloque 5\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('ratingsTabs005.data'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros Bloque 5: \")\n",
    "print(num_rows)\n",
    "\n",
    "#Numero de registros de los bloques 3, 4, y 5.  \n",
    "num_rows = 0\n",
    "\n",
    "for row in open('ratingsTabsFinal.data'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros totales: \")\n",
    "print(num_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 19:30:41\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "1830\n",
      "1811\n",
      "1657\n",
      "Intersección usuarios 2005-2019 : \n",
      "1637\n",
      "****************************************\n",
      "10834\n",
      "8928\n",
      "8009\n",
      "Intersección películas 2005-2019 : \n",
      "7145\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "print('****************************************')\n",
    "df003 = pd.read_csv('ratingsTabs3Final.csv', delimiter='\\t')\n",
    "df004 = pd.read_csv('ratingsTabs4Final.csv', delimiter='\\t')\n",
    "df005 = pd.read_csv('ratingsTabs5Final.csv', delimiter='\\t')\n",
    "#USUARIOS COMUNES ENTRE LOS TRES BLOQUES\n",
    "user_ids003 = df003['userId'].values.tolist()\n",
    "unique_users003 = set(user_ids003) \n",
    "print(len(unique_users003))\n",
    "\n",
    "user_ids004 = df004['userId'].values.tolist()\n",
    "unique_users004 = set(user_ids004) \n",
    "print(len(unique_users004))\n",
    "\n",
    "user_ids005 = df005['userId'].values.tolist()\n",
    "unique_users005 = set(user_ids005) \n",
    "print(len(unique_users005))\n",
    "\n",
    "result0 = unique_users003.intersection(unique_users004,unique_users005)\n",
    "resultCountTODOS = len(result0)\n",
    "print('Intersección usuarios 2005-2019 : ')\n",
    "print(resultCountTODOS)\n",
    "print('****************************************')\n",
    "#USUARIOS COMUNES ENTRE LOS TRES BLOQUES\n",
    "item_ids003 = df003['mmovieId'].values.tolist()\n",
    "unique_movies003 = set(item_ids003) \n",
    "print(len(unique_movies003))\n",
    "\n",
    "item_ids004 = df004['mmovieId'].values.tolist()\n",
    "unique_movies004 = set(item_ids004) \n",
    "print(len(unique_movies004))\n",
    "\n",
    "item_ids005 = df005['mmovieId'].values.tolist()\n",
    "unique_movies005 = set(item_ids005) \n",
    "print(len(unique_movies005))\n",
    "\n",
    "resultMovies0 = unique_movies005.intersection(unique_movies003,unique_movies004)\n",
    "resultCountTODOSMovies = len(resultMovies0)\n",
    "print('Intersección películas 2005-2019 : ')\n",
    "print(resultCountTODOSMovies)\n",
    "print('****************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 19:30:44\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESO DE PREDICCION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 20  -  train_rmse: 0.8776834712269208\n",
      "Epoch  2 / 20  -  train_rmse: 0.8401319148823951\n",
      "Epoch  3 / 20  -  train_rmse: 0.8194279115960964\n",
      "Epoch  4 / 20  -  train_rmse: 0.8059751853812179\n",
      "Epoch  5 / 20  -  train_rmse: 0.7962368554847735\n",
      "Epoch  6 / 20  -  train_rmse: 0.7886492207949225\n",
      "Epoch  7 / 20  -  train_rmse: 0.7824214877228012\n",
      "Epoch  8 / 20  -  train_rmse: 0.7771301470927207\n",
      "Epoch  9 / 20  -  train_rmse: 0.7725004180676245\n",
      "Epoch  10 / 20  -  train_rmse: 0.7683689972633821\n",
      "Epoch  11 / 20  -  train_rmse: 0.7646180999427686\n",
      "Epoch  12 / 20  -  train_rmse: 0.7611675347661425\n",
      "Epoch  13 / 20  -  train_rmse: 0.7579495342396599\n",
      "Epoch  14 / 20  -  train_rmse: 0.7549243593464666\n",
      "Epoch  15 / 20  -  train_rmse: 0.752054015994851\n",
      "Epoch  16 / 20  -  train_rmse: 0.7493075442949299\n",
      "Epoch  17 / 20  -  train_rmse: 0.7466642990349134\n",
      "Epoch  18 / 20  -  train_rmse: 0.7440959940375804\n",
      "Epoch  19 / 20  -  train_rmse: 0.7415942215931117\n",
      "Epoch  20 / 20  -  train_rmse: 0.7391452203384272\n",
      "\n",
      "Test RMSE: 0.7732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChrisLex\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################\n",
    "#PREDICCION DE RATINGS PELICULAS BLOQUE 3\n",
    "# Reload imported code \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Print all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "    \n",
    "rand_seed = 2\n",
    "np.random.seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "#TODAS LAS RECOMENDACIONES\n",
    "cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "movie_data = pd.read_csv('ratingsTabs003.data', names = cols, sep = '\\t', usecols=[0, 1, 2], engine='python')\n",
    "\n",
    "X = movie_data[['user_id', 'item_id']]\n",
    "y = movie_data['rating']\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Prepare data for online learning\n",
    "X_train_initial, y_train_initial, X_train_update, y_train_update, X_test_update, y_test_update = train_update_test_split(movie_data, frac_new_users=0.2)\n",
    "\n",
    "matrix_fact = KernelMF(n_epochs = 20, n_factors = 100, verbose = 1, lr = 0.001, reg = 0.005)\n",
    "matrix_fact.fit(X_train, y_train)\n",
    "\n",
    "pred = matrix_fact.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, pred, squared = False)\n",
    "\n",
    "print(f'\\nTest RMSE: {rmse:.4f}')\n",
    "\n",
    "\n",
    "#PROCESO DE GENERACION DE DATOS ACTUALES Y PREDICCION DE DATOS FALTANTES BLOQUE 3\n",
    "f = open('RatingsPredictions003-5.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['userId','mmovieId','rating','timestamp'])\n",
    "f.close()\n",
    "df003_5 = pd.read_csv('ratingsTabs3Final.csv', delimiter='\\t')\n",
    "\n",
    "n = 0\n",
    "\n",
    "for user in result0:\n",
    "    items_known = X_train.query('user_id == @user')['item_id']\n",
    "    listaUsuarios = list(result0)\n",
    "    listaPeliculas = list(resultMovies0)\n",
    "    \n",
    "    df = matrix_fact.recommend (user=user,amount = 20000, items_known=items_known)\n",
    "    \n",
    "    #DataFrame original filtrado por usuario \n",
    "    df003_5.get('userId', default='userId')\n",
    "    df003_5 = df003_5.loc[df003_5['userId'] == user]\n",
    "    \n",
    "    #DataFrame de prediccion filtrado por peliculas interseccion\n",
    "    y = df[df['item_id'].isin(listaPeliculas)]\n",
    "\n",
    "    #DataFrame original filtrado por peliculas interseccion\n",
    "    y1 = df003_5[df003_5['mmovieId'].isin(listaPeliculas)]\n",
    "    \n",
    "    #DataFrame solo de predicciones sin los datos originales\n",
    "    x1 = y1['mmovieId'].values.tolist()\n",
    "    \n",
    "    y0 = y[~y['item_id'].isin(x1)]\n",
    "    \n",
    "    y1.drop(['timestamp'], axis='columns', inplace=True)\n",
    "\n",
    "    y0 = y0.round({'rating_pred': 2})\n",
    "    with open('RatingsPredictions003-5.csv', 'a') as f:\n",
    "        y0.to_csv(f, header=False,index=False)\n",
    "        y1.to_csv(f, header=False,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 19:42:14\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Epoch  1 / 20  -  train_rmse: 0.8876900884607645\n",
      "Epoch  2 / 20  -  train_rmse: 0.8564474249417777\n",
      "Epoch  3 / 20  -  train_rmse: 0.8353452943746863\n",
      "Epoch  4 / 20  -  train_rmse: 0.8198148383924324\n",
      "Epoch  5 / 20  -  train_rmse: 0.8077055807490814\n",
      "Epoch  6 / 20  -  train_rmse: 0.7978417267759029\n",
      "Epoch  7 / 20  -  train_rmse: 0.7895576136709096\n",
      "Epoch  8 / 20  -  train_rmse: 0.7824118648416086\n",
      "Epoch  9 / 20  -  train_rmse: 0.7761272416084298\n",
      "Epoch  10 / 20  -  train_rmse: 0.7705017131781087\n",
      "Epoch  11 / 20  -  train_rmse: 0.765406415500531\n",
      "Epoch  12 / 20  -  train_rmse: 0.7607342843189308\n",
      "Epoch  13 / 20  -  train_rmse: 0.7564118119910059\n",
      "Epoch  14 / 20  -  train_rmse: 0.7523763521023872\n",
      "Epoch  15 / 20  -  train_rmse: 0.7485831994622609\n",
      "Epoch  16 / 20  -  train_rmse: 0.7449958817211748\n",
      "Epoch  17 / 20  -  train_rmse: 0.7415845387168349\n",
      "Epoch  18 / 20  -  train_rmse: 0.7383241822859358\n",
      "Epoch  19 / 20  -  train_rmse: 0.7351941117395353\n",
      "Epoch  20 / 20  -  train_rmse: 0.7321759135512659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KernelMF(gamma=0.01, lr=0.001, n_epochs=20, reg=0.005)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 0.7801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#########################################################################################\n",
    "#PREDICCION DE RATINGS PELICULAS BLOQUE 4\n",
    "# Reload imported code \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Print all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "    \n",
    "rand_seed = 2\n",
    "np.random.seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "#TODAS LAS RECOMENDACIONES\n",
    "cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "movie_data = pd.read_csv('ratingsTabs004.data', names = cols, sep = '\\t', usecols=[0, 1, 2], engine='python')\n",
    "\n",
    "X = movie_data[['user_id', 'item_id']]\n",
    "y = movie_data['rating']\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Prepare data for online learning\n",
    "X_train_initial, y_train_initial, X_train_update, y_train_update, X_test_update, y_test_update = train_update_test_split(movie_data, frac_new_users=0.2)\n",
    "\n",
    "\n",
    "matrix_fact = KernelMF(n_epochs = 20, n_factors = 100, verbose = 1, lr = 0.001, reg = 0.005)\n",
    "matrix_fact.fit(X_train, y_train)\n",
    "\n",
    "pred = matrix_fact.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, pred, squared = False)\n",
    "\n",
    "print(f'\\nTest RMSE: {rmse:.4f}')\n",
    "\n",
    "#PROCESO DE GENERACION DE DATOS ACTUALES + PREDICCION DE DATOS FALTANTES BLOQUE 4\n",
    "f = open('RatingsPredictions004-5.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['userId','mmovieId','rating','timestamp'])\n",
    "f.close()\n",
    "df004_5 = pd.read_csv('ratingsTabs4Final.csv', delimiter='\\t')\n",
    "\n",
    "for user in result0:\n",
    "    items_known = X_train.query('user_id == @user')['item_id']\n",
    "\n",
    "    listaUsuarios = list(result0)\n",
    "    listaPeliculas = list(resultMovies0)\n",
    "\n",
    "    df = matrix_fact.recommend (user=user,amount = 20000, items_known=items_known)\n",
    "    #DataFrame original filtrado por usuario \n",
    "    df004_5 = df004_5.loc[df004_5['userId'] == user]\n",
    "\n",
    "    #DataFrame de prediccion filtrado por peliculas interseccion\n",
    "    y = df[df['item_id'].isin(listaPeliculas)]\n",
    "\n",
    "    #DataFrame original filtrado por peliculas interseccion\n",
    "    y1 = df004_5[df004_5['mmovieId'].isin(listaPeliculas)]\n",
    "\n",
    "    #DataFrame solo de predicciones sin los datos originales \n",
    "    x1 = y1['mmovieId'].values.tolist()\n",
    "    y0 = y[~y['item_id'].isin(x1)]\n",
    "   \n",
    "    y1.drop(['timestamp'], axis='columns', inplace=True)\n",
    "    y0 = y0.round({'rating_pred': 2})\n",
    "    with open('RatingsPredictions004-5.csv', 'a') as f:\n",
    "        y0.to_csv(f, header=False,index=False)\n",
    "    with open('RatingsPredictions004-5.csv', 'a') as f:\n",
    "        y1.to_csv(f, header=False,index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 19:50:56\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Epoch  1 / 20  -  train_rmse: 0.9220585114682103\n",
      "Epoch  2 / 20  -  train_rmse: 0.897620352084276\n",
      "Epoch  3 / 20  -  train_rmse: 0.8797789194645332\n",
      "Epoch  4 / 20  -  train_rmse: 0.8654223001426707\n",
      "Epoch  5 / 20  -  train_rmse: 0.8533777511674848\n",
      "Epoch  6 / 20  -  train_rmse: 0.8430002202517085\n",
      "Epoch  7 / 20  -  train_rmse: 0.8338903636082939\n",
      "Epoch  8 / 20  -  train_rmse: 0.8257845667893473\n",
      "Epoch  9 / 20  -  train_rmse: 0.8184739433546773\n",
      "Epoch  10 / 20  -  train_rmse: 0.8118098690239068\n",
      "Epoch  11 / 20  -  train_rmse: 0.8056837223157283\n",
      "Epoch  12 / 20  -  train_rmse: 0.8000071767857524\n",
      "Epoch  13 / 20  -  train_rmse: 0.7947169873420649\n",
      "Epoch  14 / 20  -  train_rmse: 0.7897512508452035\n",
      "Epoch  15 / 20  -  train_rmse: 0.7850665736818739\n",
      "Epoch  16 / 20  -  train_rmse: 0.7806293872421978\n",
      "Epoch  17 / 20  -  train_rmse: 0.7764007824048998\n",
      "Epoch  18 / 20  -  train_rmse: 0.7723610735575321\n",
      "Epoch  19 / 20  -  train_rmse: 0.7684868089126875\n",
      "Epoch  20 / 20  -  train_rmse: 0.7647520314280792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KernelMF(gamma=0.01, lr=0.001, n_epochs=20, reg=0.005)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 0.8230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################################################################\n",
    "#PREDICCION DE RATINGS PELICULAS BLOQUE 5\n",
    "# Reload imported code \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Print all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "    \n",
    "rand_seed = 2\n",
    "np.random.seed(rand_seed)\n",
    "random.seed(rand_seed)\n",
    "\n",
    "#TODAS LAS RECOMENDACIONES\n",
    "#cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "#movie_data = pd.read_csv('ratingsTabsFinal.data', names = cols, sep = '\\t', usecols=[0, 1, 2], engine='python')\n",
    "\n",
    "cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "movie_data = pd.read_csv('ratingsTabs005.data', names = cols, sep = '\\t', usecols=[0, 1, 2], engine='python')\n",
    "\n",
    "X = movie_data[['user_id', 'item_id']]\n",
    "y = movie_data['rating']\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Prepare data for online learning\n",
    "X_train_initial, y_train_initial, X_train_update, y_train_update, X_test_update, y_test_update = train_update_test_split(movie_data, frac_new_users=0.2)\n",
    "\n",
    "\n",
    "matrix_fact = KernelMF(n_epochs = 20, n_factors = 100, verbose = 1, lr = 0.001, reg = 0.005)\n",
    "matrix_fact.fit(X_train, y_train)\n",
    "\n",
    "pred = matrix_fact.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, pred, squared = False)\n",
    "\n",
    "print(f'\\nTest RMSE: {rmse:.4f}')\n",
    "\n",
    "#PROCESO DE GENERACION DE DATOS ACTUALES Y PREDICCION DE DATOS FALTANTES BLOQUE 5\n",
    "f = open('RatingsPredictions005-5.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['userId','mmovieId','rating','timestamp'])\n",
    "f.close()\n",
    "df005_5 = pd.read_csv('ratingsTabs5Final.csv', delimiter='\\t')\n",
    "\n",
    "for user in result0:\n",
    "    items_known = X_train.query('user_id == @user')['item_id']\n",
    "\n",
    "    listaUsuarios = list(result0)\n",
    "    listaPeliculas = list(resultMovies0)\n",
    "\n",
    "    df = matrix_fact.recommend (user=user,amount = 20000, items_known=items_known)\n",
    "    #DataFrame original filtrado por usuario \n",
    "    df005_5 = df005_5.loc[df005_5['userId'] == user]\n",
    "\n",
    "    #DataFrame de prediccion filtrado por peliculas interseccion\n",
    "    y = df[df['item_id'].isin(listaPeliculas)]\n",
    "\n",
    "    #DataFrame original filtrado por peliculas interseccion\n",
    "    y1 = df005_5[df005_5['mmovieId'].isin(listaPeliculas)]\n",
    "\n",
    "    #DataFrame solo de predicciones sin los datos originales\n",
    "    x1 = y1['mmovieId'].values.tolist()\n",
    "    y0 = y[~y['item_id'].isin(x1)]\n",
    "    #y0 = y\n",
    "    y1.drop(['timestamp'], axis='columns', inplace=True)\n",
    "    y0 = y0.round({'rating_pred': 2})\n",
    "    with open('RatingsPredictions005-5.csv', 'a') as f:\n",
    "        y0.to_csv(f, header=False,index=False)\n",
    "    with open('RatingsPredictions005-5.csv', 'a') as f:\n",
    "        y1.to_csv(f, header=False,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 19:54:26\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"RatingsPredictions003-5.dat\")\n",
    "os.remove(\"RatingsPredictions004-5.dat\")\n",
    "os.remove(\"RatingsPredictions005-5.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CSV to tab-delimited file...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################################\n",
    "\n",
    "#PROCESO DE TRANSFOMACION DE CSV A ARCHIVOS DAT\n",
    "\n",
    "# Convert comma-delimited CSV files to pipe-delimited files\n",
    "# Usage: Drag-and-drop CSV file over script to convert it.\n",
    "\n",
    "print(\"Converting CSV to tab-delimited file...\")\n",
    "#BLOQUE 3\n",
    "inputPath3 = 'RatingsPredictions003-5.csv'\n",
    "outputPath3 = 'RatingsPredictions003-5.dat'\n",
    "with open(inputPath3) as inputFile:\n",
    "  with open(outputPath3, 'w', newline='') as outputFile:\n",
    "    reader = csv.DictReader(inputFile, delimiter=',')\n",
    "    writer = csv.DictWriter(outputFile, reader.fieldnames, delimiter='\\t')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(reader)\n",
    "  \n",
    "with open(outputPath3, 'r') as fin:\n",
    "    data = fin.read().splitlines(True)\n",
    "with open(outputPath3, 'w') as fout:\n",
    "    fout.writelines(data[1:])\n",
    "\n",
    "#BLOQUE 4\n",
    "inputPath4 = 'RatingsPredictions004-5.csv'\n",
    "outputPath4 = 'RatingsPredictions004-5.dat'\n",
    "with open(inputPath4) as inputFile:\n",
    "  with open(outputPath4, 'w', newline='') as outputFile:\n",
    "    reader = csv.DictReader(inputFile, delimiter=',')\n",
    "    writer = csv.DictWriter(outputFile, reader.fieldnames, delimiter='\\t')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(reader)\n",
    "with open(outputPath4, 'r') as fin:\n",
    "    data = fin.read().splitlines(True)\n",
    "with open(outputPath4, 'w') as fout:\n",
    "    fout.writelines(data[1:])\n",
    "\n",
    "#BLOQUE 5\n",
    "inputPath5 = 'RatingsPredictions005-5.csv'\n",
    "outputPath5 = 'RatingsPredictions005-5.dat'\n",
    "with open(inputPath5) as inputFile:\n",
    "  with open(outputPath5, 'w', newline='') as outputFile:\n",
    "    reader = csv.DictReader(inputFile, delimiter=',')\n",
    "    writer = csv.DictWriter(outputFile, reader.fieldnames, delimiter='\\t')\n",
    "    writer.writeheader()\n",
    "    writer.writerows(reader)\n",
    "with open(outputPath5, 'r') as fin:\n",
    "    data = fin.read().splitlines(True)\n",
    "with open(outputPath5, 'w') as fout:\n",
    "    fout.writelines(data[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 20:03:03\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersección usuarios 2005-2019 : \n",
      "1637\n",
      "Intersección películas 2005-2019 : \n",
      "7076\n"
     ]
    }
   ],
   "source": [
    "#USUARIOS COMUNES ENTRE LOS TRES BLOQUES\n",
    "df003 = pd.read_csv('RatingsPredictions003-5.csv')\n",
    "df004 = pd.read_csv('RatingsPredictions004-5.csv')\n",
    "df005 = pd.read_csv('RatingsPredictions005-5.csv')\n",
    "\n",
    "user_ids003 = df003['userId'].values.tolist()\n",
    "unique_users003 = set(user_ids003) \n",
    "\n",
    "user_ids004 = df004['userId'].values.tolist()\n",
    "unique_users004 = set(user_ids004) \n",
    "\n",
    "user_ids005 = df005['userId'].values.tolist()\n",
    "unique_users005 = set(user_ids005) \n",
    "\n",
    "result1 = unique_users003.intersection(unique_users004,unique_users005)\n",
    "resultCountTODOS = len(result1)\n",
    "print('Intersección usuarios 2005-2019 : ')\n",
    "print(resultCountTODOS)\n",
    "\n",
    "#PELICULAS COMUNES ENTRE LOS TRES BLOQUES\n",
    "item_ids003 = df003['mmovieId'].values.tolist()\n",
    "unique_movies003 = set(item_ids003) \n",
    "\n",
    "item_ids004 = df004['mmovieId'].values.tolist()\n",
    "unique_movies004 = set(item_ids004) \n",
    "\n",
    "item_ids005 = df005['mmovieId'].values.tolist()\n",
    "unique_movies005 = set(item_ids005) \n",
    "\n",
    "resultMovies1 = unique_movies005.intersection(unique_movies003,unique_movies004)\n",
    "resultCountTODOSMovies = len(resultMovies1)\n",
    "print('Intersección películas 2005-2019 : ')\n",
    "print(resultCountTODOSMovies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros : \n",
      "11583412\n"
     ]
    }
   ],
   "source": [
    "print('Total de registros : ')\n",
    "print(resultCountTODOS*resultCountTODOSMovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de registros Bloque 3: \n",
      "11232488\n",
      "Numero de registros Bloque 4: \n",
      "11493552\n",
      "Numero de registros Bloque 5: \n",
      "11547233\n"
     ]
    }
   ],
   "source": [
    "#Numero de registros Bloque 3\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('RatingsPredictions003-5.dat'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros Bloque 3: \")\n",
    "print(num_rows)\n",
    "\n",
    "#Numero de registros Bloque 4\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('RatingsPredictions004-5.dat'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros Bloque 4: \")\n",
    "print(num_rows)\n",
    "\n",
    "\n",
    "#Numero de registros Bloque 5\n",
    "num_rows = 0\n",
    "\n",
    "for row in open('RatingsPredictions005-5.dat'):\n",
    "    num_rows += 1\n",
    "\n",
    "print(\"Numero de registros Bloque 5: \")\n",
    "print(num_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 20:03:49\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios-Peliculas comunes entre los bloques 3,4 y 5 (2005-2019) : \n",
      "10881486\n"
     ]
    }
   ],
   "source": [
    "#IDENTIFICACION DE REGISTROS UNICOS CON COMBINACION USUARIO-PELICULA\n",
    "df003 = pd.read_csv('RatingsPredictions003-5.csv')\n",
    "df004 = pd.read_csv('RatingsPredictions004-5.csv')\n",
    "df005 = pd.read_csv('RatingsPredictions005-5.csv')\n",
    "\n",
    "#USUARIOS COMUNES PARA LOS BLOQUES 3,4 Y 5\n",
    "#Bloque 3\n",
    "\n",
    "df003['userId'] = df003['userId'].apply(str)\n",
    "df003['mmovieId'] = df003['mmovieId'].apply(str)\n",
    "df003['unique'] = df003['userId']+df003['mmovieId']\n",
    "\n",
    "df004['userId'] = df004['userId'].apply(str)\n",
    "df004['mmovieId'] = df004['mmovieId'].apply(str)\n",
    "df004['unique'] = df004['userId']+df004['mmovieId']\n",
    "\n",
    "df005['userId'] = df005['userId'].apply(str)\n",
    "df005['mmovieId'] = df005['mmovieId'].apply(str)\n",
    "df005['unique'] = df005['userId']+df005['mmovieId']\n",
    "\n",
    "#Usuarios únicos del bloque 3\n",
    "user_ids003 = df003['unique'].values.tolist()\n",
    "unique_UM003 = set(user_ids003) \n",
    "\n",
    "#Usuarios únicos del bloque 4\n",
    "user_ids004 = df004['unique'].values.tolist()\n",
    "unique_UM004 = set(user_ids004) \n",
    "\n",
    "#Usuarios únicos del bloque 5\n",
    "user_ids005 = df005['unique'].values.tolist()\n",
    "unique_UM005 = set(user_ids005) \n",
    "\n",
    "#Intersección de usuarios de los tres bloques \n",
    "resultUM = unique_UM003.intersection(unique_UM004,unique_UM005)\n",
    "resultContUM = len(resultUM)\n",
    "print('Usuarios-Peliculas comunes entre los bloques 3,4 y 5 (2005-2019) : ')\n",
    "print(resultContUM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChrisLex\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           userId mmovieId  rating  timestamp          unique\n",
      "2395663  100060.0      1.0    3.97        NaN     100060.01.0\n",
      "2398352  100060.0     10.0    3.67        NaN    100060.010.0\n",
      "2399386  100060.0    100.0    3.59        NaN   100060.0100.0\n",
      "2401166  100060.0   1003.0    3.37        NaN  100060.01003.0\n",
      "2400455  100060.0   1004.0    3.49        NaN  100060.01004.0\n",
      "...           ...      ...     ...        ...             ...\n",
      "2047862   99825.0    993.0    3.43        NaN    99825.0993.0\n",
      "2044850   99825.0    994.0    3.77        NaN    99825.0994.0\n",
      "2049688   99825.0    996.0    3.27        NaN    99825.0996.0\n",
      "2049949   99825.0    998.0    3.23        NaN    99825.0998.0\n",
      "2047462   99825.0    999.0    3.46        NaN    99825.0999.0\n",
      "\n",
      "[10881486 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChrisLex\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           userId mmovieId  rating  timestamp          unique\n",
      "2443658  100060.0      1.0    4.10        NaN     100060.01.0\n",
      "2450153  100060.0     10.0    3.50        NaN    100060.010.0\n",
      "2449507  100060.0    100.0    3.65        NaN   100060.0100.0\n",
      "2445939  100060.0   1003.0    3.85        NaN  100060.01003.0\n",
      "2449571  100060.0   1004.0    3.64        NaN  100060.01004.0\n",
      "...           ...      ...     ...        ...             ...\n",
      "2086694   99825.0    993.0    3.55        NaN    99825.0993.0\n",
      "2084756   99825.0    994.0    3.73        NaN    99825.0994.0\n",
      "2088257   99825.0    996.0    3.46        NaN    99825.0996.0\n",
      "2087141   99825.0    998.0    3.52        NaN    99825.0998.0\n",
      "2086179   99825.0    999.0    3.58        NaN    99825.0999.0\n",
      "\n",
      "[10881486 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChrisLex\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           userId mmovieId  rating  timestamp          unique\n",
      "2452809  100060.0      1.0    3.79        NaN     100060.01.0\n",
      "2453963  100060.0     10.0    3.45        NaN    100060.010.0\n",
      "2455836  100060.0    100.0    3.34        NaN   100060.0100.0\n",
      "2454809  100060.0   1003.0    3.40        NaN  100060.01003.0\n",
      "2457845  100060.0   1004.0    3.25        NaN  100060.01004.0\n",
      "...           ...      ...     ...        ...             ...\n",
      "2093717   99825.0    993.0    3.48        NaN    99825.0993.0\n",
      "2094853   99825.0    994.0    3.39        NaN    99825.0994.0\n",
      "2096073   99825.0    996.0    3.33        NaN    99825.0996.0\n",
      "2097410   99825.0    998.0    3.27        NaN    99825.0998.0\n",
      "2097785   99825.0    999.0    3.25        NaN    99825.0999.0\n",
      "\n",
      "[10881486 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#PROCESO DE FILTRADO DE BLOQUES CON DIMENSION (Usuario - Pelicula) SIMILAR PARA LOS TRES BLOQUES CON DATOS ORIGINALES \n",
    "# Y CON LOS DATOS PREDICCION\n",
    "import csv  \n",
    "\n",
    "listaUsuariosPeliculas = list(resultUM)\n",
    "\n",
    "#BLOQUE 3\n",
    "df003['uniqueVAL'] = df003['unique'].isin(listaUsuariosPeliculas)\n",
    "df003_1 = df003.loc[df003['uniqueVAL'] == True]\n",
    "df003_1.drop('uniqueVAL',axis='columns', inplace=True)\n",
    "df003_1.to_csv('test003tt.csv', index=False)\n",
    "print(df003_1.sort_values(by=['unique']))\n",
    "\n",
    "df004['uniqueVAL'] = df004['unique'].isin(listaUsuariosPeliculas)\n",
    "df004_1 = df004.loc[df004['uniqueVAL'] == True]\n",
    "df004_1.drop('uniqueVAL',axis='columns', inplace=True)\n",
    "df004_1.to_csv('test004tt.csv', index=False)\n",
    "print(df004_1.sort_values(by=['unique']))\n",
    "\n",
    "df005['uniqueVAL'] = df005['unique'].isin(listaUsuariosPeliculas)\n",
    "df005_1 = df005.loc[df005['uniqueVAL'] == True]\n",
    "df005_1.drop('uniqueVAL',axis='columns', inplace=True)\n",
    "df005_1.to_csv('test005tt.csv', index=False)\n",
    "print(df005_1.sort_values(by=['unique']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 20:10:21\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************\n",
      "1637\n",
      "1637\n",
      "1637\n",
      "Intersección usuarios 2005-2019 : \n",
      "1637\n",
      "********************************\n",
      "7076\n",
      "7076\n",
      "7076\n",
      "Intersección películas 2005-2019 : \n",
      "7076\n",
      "********************************\n"
     ]
    }
   ],
   "source": [
    "#VALIDACION DE DIMENSION DE MATRICES PARA CADA BLOQUE\n",
    "print(\"********************************\")\n",
    "df003 = pd.read_csv('test003tt.csv')\n",
    "df004 = pd.read_csv('test004tt.csv')\n",
    "df005 = pd.read_csv('test005tt.csv')\n",
    "\n",
    "#USUARIOS COMUNES ENTRE LOS TRES BLOQUES\n",
    "user_ids003 = df003['userId'].values.tolist()\n",
    "unique_users003 = set(user_ids003) \n",
    "print(len(unique_users003))\n",
    "\n",
    "user_ids004 = df004['userId'].values.tolist()\n",
    "unique_users004 = set(user_ids004) \n",
    "print(len(unique_users004))\n",
    "\n",
    "user_ids005 = df005['userId'].values.tolist()\n",
    "unique_users005 = set(user_ids005) \n",
    "print(len(unique_users005))\n",
    "\n",
    "result = unique_users003.intersection(unique_users004,unique_users005)\n",
    "resultCountTODOS = len(result)\n",
    "print('Intersección usuarios 2005-2019 : ')\n",
    "print(resultCountTODOS)\n",
    "print(\"********************************\")\n",
    "#USUARIOS COMUNES ENTRE LOS TRES BLOQUES\n",
    "item_ids003 = df003['mmovieId'].values.tolist()\n",
    "unique_movies003 = set(item_ids003) \n",
    "print(len(unique_movies003))\n",
    "\n",
    "item_ids004 = df004['mmovieId'].values.tolist()\n",
    "unique_movies004 = set(item_ids004) \n",
    "print(len(unique_movies004))\n",
    "\n",
    "item_ids005 = df005['mmovieId'].values.tolist()\n",
    "unique_movies005 = set(item_ids005) \n",
    "print(len(unique_movies005))\n",
    "\n",
    "resultMovies = unique_movies005.intersection(unique_movies003,unique_movies004)\n",
    "resultCountTODOSMovies = len(resultMovies)\n",
    "print('Intersección películas 2005-2019 : ')\n",
    "print(resultCountTODOSMovies)\n",
    "print(\"********************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 20:11:54\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"ratingsTabs3Final.data\")\n",
    "os.remove(\"ratingsTabs4Final.data\")\n",
    "os.remove(\"ratingsTabs5Final.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ratingsTabs3Final.data'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'ratingsTabs4Final.data'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'ratingsTabs5Final.data'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"\\n#Transformación de extensión de archivos .data .csv\\npre, ext = os.path.splitext('ratingsTabs3Final.data')\\nos.rename('ratingsTabs3Final.data', pre + '.csv')\\n\\npre, ext = os.path.splitext('ratingsTabs4Final.data')\\nos.rename('ratingsTabs4Final.data', pre + '.csv')\\n\\npre, ext = os.path.splitext('ratingsTabs5Final.data')\\nos.rename('ratingsTabs5Final.data', pre + '.csv')\\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PROCESO DE COPIA DE ARCHIVOS .DATA\n",
    "import shutil\n",
    "original3 = 'ratingsTabs003Final.data'\n",
    "target3 = 'ratingsTabs3Final.data'\n",
    "shutil.copyfile(original3, target3)\n",
    "\n",
    "original4 = 'ratingsTabs004Final.data'\n",
    "target4 = 'ratingsTabs4Final.data'\n",
    "shutil.copyfile(original4, target4)\n",
    "\n",
    "original5 = 'ratingsTabs005Final.data'\n",
    "target5 =   'ratingsTabs5Final.data'\n",
    "shutil.copyfile(original5, target5)\n",
    "'''\n",
    "#Transformación de extensión de archivos .data .csv\n",
    "pre, ext = os.path.splitext('ratingsTabs3Final.data')\n",
    "os.rename('ratingsTabs3Final.data', pre + '.csv')\n",
    "\n",
    "pre, ext = os.path.splitext('ratingsTabs4Final.data')\n",
    "os.rename('ratingsTabs4Final.data', pre + '.csv')\n",
    "\n",
    "pre, ext = os.path.splitext('ratingsTabs5Final.data')\n",
    "os.rename('ratingsTabs5Final.data', pre + '.csv')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 20:11:55\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESO DE GENERACIÓN DE ARCHIVOS CON LOS DATOS DE PREDICCION + DATOS RATING ORGINALES BLOQUE3\n",
    "#ORIGINAL\n",
    "df003Orig = pd.read_csv('ratingsTabs3Final.csv',delimiter='\\t')\n",
    "\n",
    "#USUARIOS COMUNES PARA LOS BLOQUES 3,4 Y 5 ORIGINALES\n",
    "#Bloque 3 datos reales\n",
    "df003Orig['userId'] = df003Orig['userId'].apply(str)\n",
    "df003Orig['mmovieId'] = df003Orig['mmovieId'].apply(str)\n",
    "df003Orig['unique'] = df003Orig['userId'].apply(str)+df003Orig['mmovieId'].apply(str)\n",
    "\n",
    "#Bloque 3 datos predicción\n",
    "df003Pred = pd.read_csv('test003tt.csv')\n",
    "df003Pred['userId'] = df003Pred['userId'].apply(str)\n",
    "df003Pred['mmovieId'] = df003Pred['mmovieId'].apply(str)\n",
    "df003Pred['unique'] = df003Pred['userId'].apply(str)+df003Pred['mmovieId'].apply(str)\n",
    "\n",
    "#Valores Unicos Usuario-Pelicula Originales\n",
    "unique_Orig = set(df003Orig['unique'].values.tolist())\n",
    "\n",
    "#Filtrado de datos de predicción sin datos originales\n",
    "df003Pred['uniqueVAL'] = df003Pred['unique'].isin(unique_Orig)\n",
    "df003pred1 = df003Pred.loc[df003Pred['uniqueVAL'] == True]\n",
    "df003pred2 = df003Pred.loc[df003Pred['uniqueVAL'] == False]\n",
    "\n",
    "#lista de valores Unicos Usuario-Pelicula Originales Predicción\n",
    "unique_PredTrue = set(df003pred1['unique'].values.tolist())\n",
    "\n",
    "#Filtrado de datos originales con coincidencia con datos de predicción\n",
    "df003Orig['uniqueVAL'] = df003Orig['unique'].isin(unique_PredTrue)\n",
    "df003Orig1 = df003Orig.loc[df003Orig['uniqueVAL'] == True]\n",
    "\n",
    "#Union de datos unicos Usuario-Pelicula (ORIGINALES + PREDICCION)\n",
    "df003Final = pd.concat([df003pred2, df003Orig1], ignore_index=True)\n",
    "df003Final.drop('unique',axis='columns', inplace=True)\n",
    "df003Final.drop('uniqueVAL',axis='columns', inplace=True)\n",
    "df003Final.drop('timestamp',axis='columns', inplace=True)\n",
    "df003Final.to_csv('RatingsPredictions3-5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 20:13:37\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESO DE GENERACIÓN DE ARCHIVOS CON LOS DATOS DE PREDICCION + DATOS RATING ORGINALES BLOQUE4\n",
    "#ORIGINAL\n",
    "df004Orig = pd.read_csv('ratingsTabs4Final.csv',delimiter='\\t')\n",
    "\n",
    "#Bloque 4 datos reales\n",
    "df004Orig['userId'] = df004Orig['userId'].apply(str)\n",
    "df004Orig['mmovieId'] = df004Orig['mmovieId'].apply(str)\n",
    "df004Orig['unique'] = df004Orig['userId'].apply(str)+df004Orig['mmovieId'].apply(str)\n",
    "\n",
    "#Bloque 4 datos predicción\n",
    "df004Pred = pd.read_csv('test004tt.csv')\n",
    "df004Pred['userId'] = df004Pred['userId'].apply(str)\n",
    "df004Pred['mmovieId'] = df004Pred['mmovieId'].apply(str)\n",
    "df004Pred['unique'] = df004Pred['userId'].apply(str)+df004Pred['mmovieId'].apply(str)\n",
    "\n",
    "#Valores Unicos Usuario-Pelicula Originales\n",
    "unique_Orig = set(df004Orig['unique'].values.tolist())\n",
    "\n",
    "#Filtrado de datos de predicción sin datos originales\n",
    "df004Pred['uniqueVAL'] = df004Pred['unique'].isin(unique_Orig)\n",
    "df004pred1 = df004Pred.loc[df004Pred['uniqueVAL'] == True]\n",
    "df004pred2 = df004Pred.loc[df004Pred['uniqueVAL'] == False]\n",
    "\n",
    "#lista de valores Unicos Usuario-Pelicula Originales Predicción\n",
    "unique_PredTrue = set(df004pred1['unique'].values.tolist())\n",
    "\n",
    "\n",
    "#Filtrado de datos originales con coincidencia con datos de predicción\n",
    "df004Orig['uniqueVAL'] = df004Orig['unique'].isin(unique_PredTrue)\n",
    "df004Orig1 = df004Orig.loc[df004Orig['uniqueVAL'] == True]\n",
    "\n",
    "\n",
    "#Union de datos unicos Usuario-Pelicula (ORIGINALES + PREDICCION)\n",
    "df004Final = pd.concat([df004pred2, df004Orig1], ignore_index=True)\n",
    "df004Final.drop('unique',axis='columns', inplace=True)\n",
    "df004Final.drop('uniqueVAL',axis='columns', inplace=True)\n",
    "df004Final.drop('timestamp',axis='columns', inplace=True)\n",
    "df004Final.to_csv('RatingsPredictions4-5.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 20:16:35\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESO DE GENERACIÓN DE ARCHIVOS CON LOS DATOS DE PREDICCION + DATOS RATING ORGINALES BLOQUE5\n",
    "#ORIGINAL\n",
    "df005Orig = pd.read_csv('ratingsTabs5Final.csv',delimiter='\\t')\n",
    "\n",
    "#Bloque 5 datos reales\n",
    "df005Orig['userId'] = df005Orig['userId'].apply(str)\n",
    "df005Orig['mmovieId'] = df005Orig['mmovieId'].apply(str)\n",
    "df005Orig['unique'] = df005Orig['userId'].apply(str)+df005Orig['mmovieId'].apply(str)\n",
    "\n",
    "#Bloque 5 datos predicción\n",
    "df005Pred = pd.read_csv('test005tt.csv')\n",
    "df005Pred['userId'] = df005Pred['userId'].apply(str)\n",
    "df005Pred['mmovieId'] = df005Pred['mmovieId'].apply(str)\n",
    "df005Pred['unique'] = df005Pred['userId'].apply(str)+df005Pred['mmovieId'].apply(str)\n",
    "\n",
    "#Valores Unicos Usuario-Pelicula Originales\n",
    "unique_Orig = set(df005Orig['unique'].values.tolist())\n",
    "\n",
    "#Filtrado de datos de predicción sin datos originales\n",
    "df005Pred['uniqueVAL'] = df005Pred['unique'].isin(unique_Orig)\n",
    "df005pred1 = df005Pred.loc[df005Pred['uniqueVAL'] == True]\n",
    "df005pred2 = df005Pred.loc[df005Pred['uniqueVAL'] == False]\n",
    "\n",
    "#lista de valores Unicos Usuario-Pelicula Originales Predicción\n",
    "unique_PredTrue = set(df005pred1['unique'].values.tolist())\n",
    "\n",
    "\n",
    "#Filtrado de datos originales con coincidencia con datos de predicción\n",
    "df005Orig['uniqueVAL'] = df005Orig['unique'].isin(unique_PredTrue)\n",
    "df005Orig1 = df005Orig.loc[df005Orig['uniqueVAL'] == True]\n",
    "\n",
    "\n",
    "#Union de datos unicos Usuario-Pelicula (ORIGINALES + PREDICCION)\n",
    "df005Final = pd.concat([df005pred2, df005Orig1], ignore_index=True)\n",
    "df005Final.drop('unique',axis='columns', inplace=True)\n",
    "df005Final.drop('uniqueVAL',axis='columns', inplace=True)\n",
    "df005Final.drop('timestamp',axis='columns', inplace=True)\n",
    "df005Final.to_csv('RatingsPredictions5-5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 09 01 2022 20:18:16\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%d %m %Y %H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
